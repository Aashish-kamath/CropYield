{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458c3d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing...\n",
      "Dataset shape after preprocessing: (31630, 7)\n",
      "\n",
      "Exploratory Data Analysis...\n",
      "\n",
      "Feature Engineering...\n",
      "Number of features: 22 (Numerical: 11, Categorical: 11)\n",
      "\n",
      "Performing Feature Selection...\n",
      "Selected top 15 features:\n",
      "1. crop_Potatoes_True\n",
      "2. crop_Cassava_True\n",
      "3. crop_Sweet potatoes_True\n",
      "4. crop_Potatoes_False\n",
      "5. temp_rain_interaction\n",
      "6. pesticide_per_temp\n",
      "7. average_rain_fall_mm_per_year\n",
      "8. rain_squared\n",
      "9. crop_Sorghum_False\n",
      "10. temp_squared\n",
      "11. log_pesticides\n",
      "12. avg_temp\n",
      "13. crop_Yams_True\n",
      "14. pesticides_tonnes\n",
      "15. crop_Soybeans_False\n",
      "\n",
      "Model Evaluation with Cross-Validation:\n",
      "Evaluating Linear Regression...\n",
      "  RMSE: 0.585 ± 0.007\n",
      "  R2: 0.697 ± 0.007\n",
      "Evaluating Ridge Regression...\n",
      "  RMSE: 0.585 ± 0.007\n",
      "  R2: 0.697 ± 0.007\n",
      "Evaluating Lasso Regression...\n",
      "  RMSE: 0.585 ± 0.007\n",
      "  R2: 0.697 ± 0.006\n",
      "Evaluating Random Forest...\n",
      "  RMSE: 0.453 ± 0.005\n",
      "  R2: 0.819 ± 0.005\n",
      "Evaluating Gradient Boosting...\n",
      "  RMSE: 0.479 ± 0.007\n",
      "  R2: 0.797 ± 0.005\n",
      "Evaluating XGBoost...\n",
      "  RMSE: 0.399 ± 0.004\n",
      "  R2: 0.859 ± 0.003\n",
      "Evaluating SVR...\n",
      "  RMSE: 0.488 ± 0.009\n",
      "  R2: 0.789 ± 0.008\n",
      "\n",
      "Best model based on cross-validation: XGBoost\n",
      "Training Linear Regression on full training set...\n",
      "  RMSE: 48939.322\n",
      "  R2: 0.645\n",
      "  MAE: 28368.274\n",
      "Training Ridge Regression on full training set...\n",
      "  RMSE: 48901.620\n",
      "  R2: 0.646\n",
      "  MAE: 28339.423\n",
      "Training Lasso Regression on full training set...\n",
      "  RMSE: 49018.767\n",
      "  R2: 0.644\n",
      "  MAE: 28354.182\n",
      "Training Random Forest on full training set...\n",
      "  RMSE: 24609.768\n",
      "  R2: 0.910\n",
      "  MAE: 12124.789\n",
      "Training Gradient Boosting on full training set...\n",
      "  RMSE: 38437.675\n",
      "  R2: 0.781\n",
      "  MAE: 21378.669\n",
      "Training XGBoost on full training set...\n",
      "  RMSE: 26402.713\n",
      "  R2: 0.897\n",
      "  MAE: 14057.502\n",
      "Training SVR on full training set...\n",
      "  RMSE: 35332.509\n",
      "  R2: 0.815\n",
      "  MAE: 19192.147\n",
      "\n",
      "Best model based on test set: Random Forest\n",
      "\n",
      "Analysis completed. All visualizations have been saved.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFECV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set a consistent style for all plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Load the dataset\n",
    "df_yield = pd.read_csv(\"/Users/ash/CropYield_estimation /DATASET/yield.csv\")\n",
    "df_temp = pd.read_csv(\"/Users/ash/CropYield_estimation /DATASET/temp.csv\")\n",
    "df_rainfall = pd.read_csv(\"/Users/ash/CropYield_estimation /DATASET/rainfall.csv\")\n",
    "df_pesticides = pd.read_csv(\"/Users/ash/CropYield_estimation /DATASET/pesticides.csv\")\n",
    "df_yield_df = pd.read_csv(\"/Users/ash/CropYield_estimation /DATASET/yield_df.csv\")\n",
    "\n",
    "# Data preprocessing\n",
    "print(\"Data Preprocessing...\")\n",
    "if 'Unnamed: 0' in df_yield_df.columns:\n",
    "    df_yield_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df_rainfall.rename(columns={' Area':'Area'}, inplace=True)\n",
    "df_temp.rename(columns={'year':'Year', 'country':'Area'}, inplace=True)\n",
    "\n",
    "# Merge datasets\n",
    "df_temprain = pd.merge(df_rainfall, df_temp, on=['Year','Area'])\n",
    "df_trp = pd.merge(df_temprain, df_pesticides, on=['Year','Area'])\n",
    "yield_df = pd.merge(df_yield_df, df_yield, on=['Year','Area','Item'])\n",
    "\n",
    "# Clean and prepare the final dataset\n",
    "Yield_final_data = yield_df.copy()\n",
    "columns_to_drop = ['Area Code', 'Year Code', 'Domain', 'Domain Code', 'Item Code', \n",
    "                   'Element', 'Element Code', 'Unit', 'Value']\n",
    "Yield_final_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Split 'Item' column with multiple crops\n",
    "Yield_final_data['Item'] = Yield_final_data['Item'].str.split(', ')\n",
    "Yield_final_data = Yield_final_data.explode('Item').reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset shape after preprocessing: {Yield_final_data.shape}\")\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "print(\"\\nExploratory Data Analysis...\")\n",
    "\n",
    "# Distribution of target variable\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(Yield_final_data['hg/ha_yield'], kde=True)\n",
    "plt.title('Distribution of Crop Yield')\n",
    "plt.xlabel('Yield (hg/ha)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('yield_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Log transform of target for better distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(np.log1p(Yield_final_data['hg/ha_yield']), kde=True)\n",
    "plt.title('Distribution of Log-transformed Crop Yield')\n",
    "plt.xlabel('Log(Yield+1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('log_yield_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Yield by crop type\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Item', y='hg/ha_yield', data=Yield_final_data)\n",
    "plt.title('Yield Distribution by Crop Type')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('yield_by_crop.png')\n",
    "plt.close()\n",
    "\n",
    "# Correlation between numerical features\n",
    "numerical_features = ['Year', 'average_rain_fall_mm_per_year', 'avg_temp', 'pesticides_tonnes', 'hg/ha_yield']\n",
    "correlation_matrix = Yield_final_data[numerical_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Feature Engineering\n",
    "print(\"\\nFeature Engineering...\")\n",
    "\n",
    "# 1. Create binary features for each crop type\n",
    "crop_dummies = pd.get_dummies(Yield_final_data['Item'], prefix='crop')\n",
    "Yield_final_data = pd.concat([Yield_final_data, crop_dummies], axis=1)\n",
    "\n",
    "# 2. Create interaction features\n",
    "Yield_final_data['temp_rain_interaction'] = Yield_final_data['avg_temp'] * Yield_final_data['average_rain_fall_mm_per_year']\n",
    "Yield_final_data['pesticide_per_temp'] = Yield_final_data['pesticides_tonnes'] / (Yield_final_data['avg_temp'] + 1e-6)\n",
    "Yield_final_data['rain_squared'] = Yield_final_data['average_rain_fall_mm_per_year'] ** 2\n",
    "Yield_final_data['temp_squared'] = Yield_final_data['avg_temp'] ** 2\n",
    "\n",
    "# 3. Log transform skewed features\n",
    "Yield_final_data['log_pesticides'] = np.log1p(Yield_final_data['pesticides_tonnes'])\n",
    "Yield_final_data['log_yield'] = np.log1p(Yield_final_data['hg/ha_yield'])\n",
    "\n",
    "# 4. Create temporal features\n",
    "Yield_final_data['year_squared'] = Yield_final_data['Year'] ** 2\n",
    "Yield_final_data['year_normalized'] = (Yield_final_data['Year'] - Yield_final_data['Year'].min()) / (Yield_final_data['Year'].max() - Yield_final_data['Year'].min())\n",
    "\n",
    "# Prepare data for modeling\n",
    "y = Yield_final_data['log_yield']  # Using log-transformed yield\n",
    "X = Yield_final_data.drop(['hg/ha_yield', 'Item', 'Area', 'log_yield'], axis=1)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = [c for c in X.columns if c.startswith('crop_')]\n",
    "numerical_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "print(f\"Number of features: {X.shape[1]} (Numerical: {len(numerical_cols)}, Categorical: {len(categorical_cols)})\")\n",
    "\n",
    "# Feature selection using a baseline model to identify important features\n",
    "print(\"\\nPerforming Feature Selection...\")\n",
    "\n",
    "# Create preprocessing pipeline for feature selection\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Split data for feature selection\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use Recursive Feature Elimination with Cross-Validation for feature selection\n",
    "base_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit preprocessor\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "numeric_features = numerical_cols\n",
    "categorical_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "all_features = np.concatenate([numeric_features, categorical_features.tolist()])\n",
    "\n",
    "# Train Random Forest to get feature importances\n",
    "rf_selector = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_selector.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': rf_selector.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances.head(15))\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importances.png')\n",
    "plt.close()\n",
    "\n",
    "# Select top features\n",
    "top_n_features = 15  # Adjust based on feature importance results\n",
    "top_features = feature_importances.head(top_n_features)['Feature'].tolist()\n",
    "\n",
    "print(f\"Selected top {top_n_features} features:\")\n",
    "for i, feature in enumerate(top_features):\n",
    "    print(f\"{i+1}. {feature}\")\n",
    "\n",
    "# Extract indices of top features from all features\n",
    "top_indices = [np.where(all_features == feature)[0][0] for feature in top_features]\n",
    "\n",
    "# Create filtered datasets with only top features\n",
    "X_train_selected = X_train_preprocessed[:, top_indices]\n",
    "X_test_selected = X_test_preprocessed[:, top_indices]\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.001),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    'SVR': SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "}\n",
    "\n",
    "# Model evaluation function with cross-validation\n",
    "def evaluate_model(model, X, y, cv=5):\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(-cv_scores)\n",
    "    r2_scores = cross_val_score(model, X, y, cv=cv, scoring='r2')\n",
    "    \n",
    "    return {\n",
    "        'RMSE': rmse_scores.mean(),\n",
    "        'RMSE_std': rmse_scores.std(),\n",
    "        'R2': r2_scores.mean(),\n",
    "        'R2_std': r2_scores.std()\n",
    "    }\n",
    "\n",
    "# Evaluate each model with cross-validation\n",
    "print(\"\\nModel Evaluation with Cross-Validation:\")\n",
    "cv_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    cv_result = evaluate_model(model, X_train_selected, y_train)\n",
    "    cv_results[name] = cv_result\n",
    "    print(f\"  RMSE: {cv_result['RMSE']:.3f} ± {cv_result['RMSE_std']:.3f}\")\n",
    "    print(f\"  R2: {cv_result['R2']:.3f} ± {cv_result['R2_std']:.3f}\")\n",
    "\n",
    "# Visualize cross-validation results\n",
    "cv_df = pd.DataFrame.from_dict(cv_results, orient='index')\n",
    "cv_df['Model'] = cv_df.index\n",
    "\n",
    "# Plot RMSE scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='RMSE', data=cv_df)\n",
    "plt.errorbar(x=range(len(cv_df)), y=cv_df['RMSE'], yerr=cv_df['RMSE_std'], fmt='none', color='black')\n",
    "plt.title('Cross-Validation RMSE by Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_rmse_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot R2 scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='R2', data=cv_df)\n",
    "plt.errorbar(x=range(len(cv_df)), y=cv_df['R2'], yerr=cv_df['R2_std'], fmt='none', color='black')\n",
    "plt.title('Cross-Validation R² Score by Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cv_r2_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Find the best model from cross-validation\n",
    "best_model_name = cv_df.sort_values('RMSE')['Model'].iloc[0]\n",
    "print(f\"\\nBest model based on cross-validation: {best_model_name}\")\n",
    "\n",
    "# Train all models on the complete training set for final evaluation\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} on full training set...\")\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    # Convert back from log scale\n",
    "    y_test_exp = np.expm1(y_test)\n",
    "    y_pred_exp = np.expm1(y_pred)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_exp, y_pred_exp)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_exp, y_pred_exp)\n",
    "    mae = mean_absolute_error(y_test_exp, y_pred_exp)\n",
    "    \n",
    "    results[name] = {\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'Model': model,\n",
    "        'Predictions': y_pred_exp\n",
    "    }\n",
    "    \n",
    "    print(f\"  RMSE: {rmse:.3f}\")\n",
    "    print(f\"  R2: {r2:.3f}\")\n",
    "    print(f\"  MAE: {mae:.3f}\")\n",
    "\n",
    "# Visualize model performance comparison\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'RMSE': [results[model]['RMSE'] for model in results],\n",
    "    'MAE': [results[model]['MAE'] for model in results],\n",
    "    'R2': [results[model]['R2'] for model in results]\n",
    "})\n",
    "\n",
    "# Plot RMSE comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='RMSE', data=metrics_df.sort_values('RMSE'))\n",
    "plt.title('Test Set RMSE by Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_rmse_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot R2 comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Model', y='R2', data=metrics_df.sort_values('R2', ascending=False))\n",
    "plt.title('Test Set R² Score by Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_r2_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# Find the best model from test set\n",
    "best_model_name = min(results, key=lambda x: results[x]['RMSE'])\n",
    "best_model = results[best_model_name]['Model']\n",
    "print(f\"\\nBest model based on test set: {best_model_name}\")\n",
    "\n",
    "# Visualize actual vs predicted values for the best model\n",
    "y_pred_best = results[best_model_name]['Predictions']\n",
    "y_test_exp = np.expm1(y_test)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test_exp, y_pred_best, alpha=0.5)\n",
    "plt.plot([y_test_exp.min(), y_test_exp.max()], [y_test_exp.min(), y_test_exp.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual Yield')\n",
    "plt.ylabel('Predicted Yield')\n",
    "plt.title(f'Actual vs Predicted Crop Yield ({best_model_name})')\n",
    "plt.tight_layout()\n",
    "plt.savefig('actual_vs_predicted.png')\n",
    "plt.close()\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test_exp - y_pred_best\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "plt.xlabel('Predicted Yield')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title(f'Residual Plot ({best_model_name})')\n",
    "plt.tight_layout()\n",
    "plt.savefig('residual_plot.png')\n",
    "plt.close()\n",
    "\n",
    "# Error distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.xlabel('Prediction Error')\n",
    "plt.title(f'Error Distribution ({best_model_name})')\n",
    "plt.tight_layout()\n",
    "plt.savefig('error_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Prediction error by crop type\n",
    "# Get original indices from test set\n",
    "test_indices = y_test.index\n",
    "\n",
    "# Create a dataframe for error analysis by category\n",
    "error_df = pd.DataFrame({\n",
    "    'Actual': y_test_exp,\n",
    "    'Predicted': y_pred_best,\n",
    "    'Error': residuals,\n",
    "    'Item': Yield_final_data.loc[test_indices, 'Item'],\n",
    "    'Year': Yield_final_data.loc[test_indices, 'Year']\n",
    "})\n",
    "\n",
    "# Error by crop type\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Item', y='Error', data=error_df)\n",
    "plt.title('Prediction Error by Crop Type')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('error_by_crop.png')\n",
    "plt.close()\n",
    "\n",
    "# Model comparison - actual vs predicted scatter plots in one figure\n",
    "plt.figure(figsize=(20, 15))\n",
    "models_to_plot = ['Linear Regression', 'Random Forest', 'Gradient Boosting', 'XGBoost']\n",
    "\n",
    "\n",
    "for i, model_name in enumerate(models_to_plot, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    y_pred = results[model_name]['Predictions']\n",
    "    plt.scatter(y_test_exp, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test_exp.min(), y_test_exp.max()], [y_test_exp.min(), y_test_exp.max()], 'k--', lw=2)\n",
    "    plt.xlabel('Actual Yield')\n",
    "    plt.ylabel('Predicted Yield')\n",
    "    plt.title(f'{model_name} (RMSE: {results[model_name][\"RMSE\"]:.2f}, R²: {results[model_name][\"R2\"]:.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_plots.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nAnalysis completed. All visualizations have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646c305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b216b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376604e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5beac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3975b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d13f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbefc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273c773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb2996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b36da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a044c014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2610d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7397164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccea837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e728312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89062355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6520e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbcc2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f796400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897e23da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdcb698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18786d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed291198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e3c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
